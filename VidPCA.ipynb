{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe37df82-331d-453e-a082-f8e572019d9c",
   "metadata": {},
   "source": [
    "## **VidPCA: PCA for Video Compression**\n",
    "### Introduction\n",
    "\n",
    "In this tutorial, we explore the application of Principal Component Analysis (PCA) using Singular Value Decomposition (SVD) for video compression, utilizing Octave as our tool. We begin our journey with a historical piece - 'Sallie Gardner at a Gallop', a video dating back to 1878."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "969c5fae-d0a0-462d-9c83-2e8a564ac6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"original_movie.gif\" style = 'width:100%;'>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"original_movie.gif\" style = 'width:100%;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02823f6d-a291-4d5a-a5b0-2e609b1df2c5",
   "metadata": {},
   "source": [
    "We first create an Octave function that turns a directory of JPEG files into a GIF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44cb79d1-c678-4939-9ee6-a200f2813916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing images\n",
    "image_directory = \"Frames/\"; image_prefix = \"ezgif-frame-\"; num_frames = 14;\n",
    "\n",
    "function createGIF(image_directory, image_prefix, output_name, num_frames)\n",
    "    % Create a GIF from a series of images\n",
    "    %\n",
    "    % Arguments:\n",
    "    %   image_directory - Directory containing the images\n",
    "    %   image_prefix - Prefix for the image files\n",
    "    %   num_frames - Number of frames in the animation\n",
    "\n",
    "    % Loop through each frame and add it to the GIF\n",
    "    for i = 1:num_frames\n",
    "        image_path = [image_directory, \"/\", image_prefix, num2str(i), \".jpg\"];\n",
    "        img = imread(image_path);\n",
    "        \n",
    "        % For the first frame, create the GIF\n",
    "        % For subsequent frames, append to the GIF\n",
    "        if i == 1\n",
    "            imwrite(img, output_name, 'gif', 'LoopCount', Inf, 'DelayTime', 0.1);\n",
    "        else\n",
    "            imwrite(img, output_name, 'gif', 'WriteMode', 'append', 'DelayTime', 0.1);\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "createGIF(image_directory, image_prefix, 'original_movie.gif', num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e347ff-6a61-47ca-a431-c30abf87c00c",
   "metadata": {},
   "source": [
    "### The tensor of frames\n",
    "\n",
    "Let's encode our images in a tensor that we can easily manipulate:\n",
    "\n",
    "`grayscaleImages(:,:,i)` will contain a matrix of values between 0 and 1 corresponding to the pixels in the i-th frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30aeaafa-2b92-410e-8c06-5c4618a0a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "% Load Images and Initialize Arrays\n",
    "first_image = imread([image_directory, \"/\", image_prefix, \"1.jpg\"]);\n",
    "image_size = size(first_image);\n",
    "grayscale_images = zeros(image_size(1), image_size(2), num_frames); % Initialize array for grayscale images\n",
    "\n",
    "for i = 1:num_frames % Create a tensor containing the frames\n",
    "    image = imread([image_directory, \"/\", image_prefix, num2str(i), \".jpg\"]);\n",
    "    if size(image, 3) == 3 % Check if the image is RGB\n",
    "        grayscale_images(:, :, i) = rgb2gray(image); % Convert to grayscale\n",
    "    else\n",
    "        grayscale_images(:, :, i) = image; % Use grayscale image directly\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6124502-4d23-4a6d-b63d-3408ea0938aa",
   "metadata": {},
   "source": [
    "We want to apply the Singular Value Decomposition, and for that we have to flatten each matrix in the tensor and make it into a vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "956c864e-3190-46bf-b586-bb8931622c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_images = zeros(image_size(1) * image_size(2), num_frames); % Initialize array for reshaped grayscale images\n",
    "\n",
    "for i = 1:num_frames % Flatten the tensor into a matrix\n",
    "    flattened_images(:, i) = grayscale_images(:, :, i)(:);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bc8c5d-666a-4c93-be8e-3abec976b1e8",
   "metadata": {},
   "source": [
    "Now we can apply the SVD to obtain the principal components (this should take a few seconds):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78faf577-1c5a-4042-adf9-ee893abe03f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "% Perform Singular Value Decomposition (SVD)\n",
    "[U, S, V] = svd(flattened_images);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fdd6d9-707e-4c92-b57f-51f25fcbbae8",
   "metadata": {},
   "source": [
    "Recall that `U` and `V` are orthogonal, whereas `S` is diagonal.\n",
    "The data of the movie is encoded in `S`. Let's have a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85b47897-2607-474b-a8cd-1640c2ee8674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans =\n",
      "\n",
      "   91283.60040\n",
      "    8885.60764\n",
      "    6836.43142\n",
      "    5497.15298\n",
      "    4494.28975\n",
      "    4310.73219\n",
      "    3834.10391\n",
      "    3636.69352\n",
      "    3458.88776\n",
      "    3184.77091\n",
      "    2998.70521\n",
      "    2883.37220\n",
      "    2843.93734\n",
      "    2472.01146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diag(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43a45e3-9cff-4b4e-b1e2-22b9da8b52aa",
   "metadata": {},
   "source": [
    "As you can see, the latter elements are smaller in size than the first ones. This indicates that some compression is viable. Let's take the first 5 entries only and set the rest to zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "379cbb9b-06b3-4615-8142-2b70bfaf4921",
   "metadata": {},
   "outputs": [],
   "source": [
    "% Number of principal components to retain\n",
    "num_components = 5;\n",
    "\n",
    "% Compress the video by retaining only a subset of the principal components\n",
    "compressed_flattened_images = U(:, 1:num_components) * S(1:num_components, 1:num_components) * V(:, 1:num_components)';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38f9fb9-73ae-41f9-a777-7b08861cbd00",
   "metadata": {},
   "source": [
    "The matrix `compressed_flattened_images` is now an approximation for the matrix `flattened_images`. Let's reconstruct our compressed movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "112c8299-180d-4885-83f3-4d5220221da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "% Reconstruct the compressed video tensor\n",
    "compressed_images = zeros(image_size(1), image_size(2), num_frames);\n",
    "for i = 1:num_frames\n",
    "    current_matrix = reshape(compressed_flattened_images(:,i), image_size);\n",
    "    % Normalize the values of the matrix to the range [0,1]\n",
    "    min_val = min(current_matrix(:));\n",
    "    max_val = max(current_matrix(:));\n",
    "    compressed_images(:, :, i) = (current_matrix - min_val) / (max_val - min_val);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc6f601-70f4-4df0-8b5a-9e3ec2603227",
   "metadata": {},
   "source": [
    "We will need an Octave function that turns our tensor back into a directory of JPEG files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "790bafe3-cd12-46c9-b06a-f6e5bea68478",
   "metadata": {},
   "outputs": [],
   "source": [
    "function saveImagesFromTensor(images_tensor, output_directory, file_prefix)\n",
    "    % Check if the output directory exists, if not create it\n",
    "    if ~exist(output_directory, 'dir')\n",
    "        mkdir(output_directory);\n",
    "    end\n",
    "\n",
    "    % Get the number of frames/images in the tensor\n",
    "    num_frames = size(images_tensor, 3);\n",
    "\n",
    "    % Iterate over each frame/image in the tensor\n",
    "    for i = 1:num_frames\n",
    "        % Extract the ith grayscale image\n",
    "        image = images_tensor(:, :, i);\n",
    "        \n",
    "        % Construct the filename for the image\n",
    "        filename = fullfile(output_directory, [file_prefix, num2str(i), '.jpg']);\n",
    "\n",
    "        % Save the image\n",
    "        imwrite(image, filename);\n",
    "    end\n",
    "end\n",
    "\n",
    "saveImagesFromTensor(compressed_images, 'CompressedFrames', 'frame_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7abb36-5e19-4ebe-9583-11a7d04c877d",
   "metadata": {},
   "source": [
    "As before, let's turn our movie into a GIF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aebfcbf3-3e7d-4f41-9d7a-fec2aa2b4ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "createGIF('CompressedFrames', 'frame_', 'compressedmovie.gif', 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "609c40bd-cc67-4e9a-972d-8a9b8bf21982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"compressedmovie.gif\" style = 'width:100%;'>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"compressedmovie.gif\" style = 'width:100%;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2997aeab-312f-44d7-97ae-b3b553f72df7",
   "metadata": {},
   "source": [
    "Notice: even though we are only using **35% of the original data**, we can still see the movement clearly. Let's keep analyzing the PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1ede9b-1da8-4c73-b07e-d749ab3c6630",
   "metadata": {},
   "source": [
    "### Principal components\n",
    "\n",
    "The components of the PCA correspond to the vectors in the matrix `U`. Let's see what the corresponding frames look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3646ec1e-1413-47b3-828e-8193242d2e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "% Construct an empty tensor for the PCA components\n",
    "PCA_images = zeros(image_size(1), image_size(2), num_frames);\n",
    "for i = 1:num_frames\n",
    "    current_matrix = reshape(U(:,i), image_size);\n",
    "    % Normalize the values of the matrix to the range [0,1]\n",
    "    min_val = min(current_matrix(:));\n",
    "    max_val = max(current_matrix(:));\n",
    "    compressed_images(:, :, i) = (current_matrix - min_val) / (max_val - min_val);\n",
    "end\n",
    "\n",
    "saveImagesFromTensor(compressed_images, 'PCAframes', 'PCA_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a11ec7ec-cdb6-4f08-8402-4891467c64f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"PCAframes/PCA_1.jpg\" style = \"width:60%\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"PCAframes/PCA_1.jpg\" style = \"width:60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb53a12-2420-4726-842e-a642313a8430",
   "metadata": {},
   "source": [
    "We can interpret this as the background, which roughly remains constant throughout the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a988e032-edb3-4d23-86f2-4674e1d82bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"PCAframes/PCA_2.jpg\" style = \"width:60%\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"PCAframes/PCA_2.jpg\" style = \"width:60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e65b57-6b07-477a-8d09-072baa7b585d",
   "metadata": {},
   "source": [
    "This one is also easy to interpret. The motion has two \"orthogonal\" states: the horse is contracted (area shaded in black) or extended (in white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90450434-43da-46d3-8065-54a086be54fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"PCAframes/PCA_3.jpg\" style = \"width:60%\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"PCAframes/PCA_3.jpg\" style = \"width:60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3d1644-12ac-46e2-aaad-a4eaae91e5cc",
   "metadata": {},
   "source": [
    "This tertiary component can be interpreted in two states as well:\n",
    "- The legs of the horse and the head of the man are either in front (in black)\n",
    "- Or they are at the back (in white)\n",
    "\n",
    "Later components are harder to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2efce8d9-48bd-48aa-a1fd-0022848f4cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"PCAframes/PCA_4.jpg\" style = \"width:60%\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"PCAframes/PCA_4.jpg\" style = \"width:60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0876bb2-7fe3-4e9b-88c2-923079fc0b85",
   "metadata": {},
   "source": [
    "This fourth component seems to be encoding the relative height of the neck and tail of the horse, as well as some of the leg movement.\n",
    "\n",
    "The least important contributions are the last components. Let's see the last one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "becdc316-8217-4489-8b31-d1bf1137d8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"PCAframes/PCA_14.jpg\" style = \"width:60%\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"PCAframes/PCA_14.jpg\" style = \"width:60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6134d287-d356-48a3-a7ec-b24b4db8e2a7",
   "metadata": {},
   "source": [
    "Even when the rank of the compressed tensor is just 2, one can get a decent idea of the movement of the horse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aa79b21b-1b02-4828-a19c-363e9a22b18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"compressedrank2.gif\" style = \"width:100%\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"compressedrank2.gif\" style = \"width:100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a397acf-c06b-44fe-bfab-5ff16bf2decc",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "By now, you've seen how Principal Component Analysis (PCA) via Singular Value Decomposition (SVD) can effectively compress video data. This tutorial with the 'Sallie Gardner at a Gallop' video illustrates PCA's capability to retain crucial visual information while significantly reducing data size. This method is particularly beneficial for situations with limited storage or bandwidth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c787e6b7-ccfa-4e0b-84ea-a6f72126f321",
   "metadata": {},
   "source": [
    "### Further exploration\n",
    "\n",
    "Feel free to apply these techniques to your own sets of frames. To get started, you can find a variety of frame files in the repository, in the folder AlternativeFrameSets, suitable for experimenting with PCA compression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "5.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
